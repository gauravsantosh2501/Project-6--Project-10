{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - Age\\n      - Sex\\n      - Body mass index\\n      - Average blood pressure\\n      - S1\\n      - S2\\n      - S3\\n      - S4\\n      - S5\\n      - S6\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttp://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.keys()\n",
    "\n",
    "print(diabetes.feature_names)\n",
    "\n",
    "diabetes.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note while reading the description one should find the input variable (values are already scaled) and target variable .Read the description carefully.\n",
    "\n",
    "diabetes.data\n",
    "\n",
    "diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
      "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "5   -0.092695 -0.044642 -0.040696 -0.019442 -0.068991 -0.079288  0.041277   \n",
      "6   -0.045472  0.050680 -0.047163 -0.015999 -0.040096 -0.024800  0.000779   \n",
      "7    0.063504  0.050680 -0.001895  0.066630  0.090620  0.108914  0.022869   \n",
      "8    0.041708  0.050680  0.061696 -0.040099 -0.013953  0.006202 -0.028674   \n",
      "9   -0.070900 -0.044642  0.039062 -0.033214 -0.012577 -0.034508 -0.024993   \n",
      "10  -0.096328 -0.044642 -0.083808  0.008101 -0.103389 -0.090561 -0.013948   \n",
      "11   0.027178  0.050680  0.017506 -0.033214 -0.007073  0.045972 -0.065491   \n",
      "12   0.016281 -0.044642 -0.028840 -0.009113 -0.004321 -0.009769  0.044958   \n",
      "13   0.005383  0.050680 -0.001895  0.008101 -0.004321 -0.015719 -0.002903   \n",
      "14   0.045341 -0.044642 -0.025607 -0.012556  0.017694 -0.000061  0.081775   \n",
      "15  -0.052738  0.050680 -0.018062  0.080401  0.089244  0.107662 -0.039719   \n",
      "16  -0.005515 -0.044642  0.042296  0.049415  0.024574 -0.023861  0.074412   \n",
      "17   0.070769  0.050680  0.012117  0.056301  0.034206  0.049416 -0.039719   \n",
      "18  -0.038207 -0.044642 -0.010517 -0.036656 -0.037344 -0.019476 -0.028674   \n",
      "19  -0.027310 -0.044642 -0.018062 -0.040099 -0.002945 -0.011335  0.037595   \n",
      "20  -0.049105 -0.044642 -0.056863 -0.043542 -0.045599 -0.043276  0.000779   \n",
      "21  -0.085430  0.050680 -0.022373  0.001215 -0.037344 -0.026366  0.015505   \n",
      "22  -0.085430 -0.044642 -0.004050 -0.009113 -0.002945  0.007767  0.022869   \n",
      "23   0.045341  0.050680  0.060618  0.031053  0.028702 -0.047347 -0.054446   \n",
      "24  -0.063635 -0.044642  0.035829 -0.022885 -0.030464 -0.018850 -0.006584   \n",
      "25  -0.067268  0.050680 -0.012673 -0.040099 -0.015328  0.004636 -0.058127   \n",
      "26  -0.107226 -0.044642 -0.077342 -0.026328 -0.089630 -0.096198  0.026550   \n",
      "27  -0.023677 -0.044642  0.059541 -0.040099 -0.042848 -0.043589  0.011824   \n",
      "28   0.052606 -0.044642 -0.021295 -0.074528 -0.040096 -0.037639 -0.006584   \n",
      "29   0.067136  0.050680 -0.006206  0.063187 -0.042848 -0.095885  0.052322   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "412  0.074401 -0.044642  0.085408  0.063187  0.014942  0.013091  0.015505   \n",
      "413 -0.052738 -0.044642 -0.000817 -0.026328  0.010815  0.007141  0.048640   \n",
      "414  0.081666  0.050680  0.006728 -0.004523  0.109883  0.117056 -0.032356   \n",
      "415 -0.005515 -0.044642  0.008883 -0.050428  0.025950  0.047224 -0.043401   \n",
      "416 -0.027310 -0.044642  0.080019  0.098763 -0.002945  0.018101 -0.017629   \n",
      "417 -0.052738 -0.044642  0.071397 -0.074528 -0.015328 -0.001314  0.004460   \n",
      "418  0.009016 -0.044642 -0.024529 -0.026328  0.098876  0.094196  0.070730   \n",
      "419 -0.020045 -0.044642 -0.054707 -0.053871 -0.066239 -0.057367  0.011824   \n",
      "420  0.023546 -0.044642 -0.036385  0.000068  0.001183  0.034698 -0.043401   \n",
      "421  0.038076  0.050680  0.016428  0.021872  0.039710  0.045032 -0.043401   \n",
      "422 -0.078165  0.050680  0.077863  0.052858  0.078236  0.064447  0.026550   \n",
      "423  0.009016  0.050680 -0.039618  0.028758  0.038334  0.073529 -0.072854   \n",
      "424  0.001751  0.050680  0.011039 -0.019442 -0.016704 -0.003819 -0.047082   \n",
      "425 -0.078165 -0.044642 -0.040696 -0.081414 -0.100638 -0.112795  0.022869   \n",
      "426  0.030811  0.050680 -0.034229  0.043677  0.057597  0.068831 -0.032356   \n",
      "427 -0.034575  0.050680  0.005650 -0.005671 -0.073119 -0.062691 -0.006584   \n",
      "428  0.048974  0.050680  0.088642  0.087287  0.035582  0.021546 -0.024993   \n",
      "429 -0.041840 -0.044642 -0.033151 -0.022885  0.046589  0.041587  0.056003   \n",
      "430 -0.009147 -0.044642 -0.056863 -0.050428  0.021822  0.045345 -0.028674   \n",
      "431  0.070769  0.050680 -0.030996  0.021872 -0.037344 -0.047034  0.033914   \n",
      "432  0.009016 -0.044642  0.055229 -0.005671  0.057597  0.044719 -0.002903   \n",
      "433 -0.027310 -0.044642 -0.060097 -0.029771  0.046589  0.019980  0.122273   \n",
      "434  0.016281 -0.044642  0.001339  0.008101  0.005311  0.010899  0.030232   \n",
      "435 -0.012780 -0.044642 -0.023451 -0.040099 -0.016704  0.004636 -0.017629   \n",
      "436 -0.056370 -0.044642 -0.074108 -0.050428 -0.024960 -0.047034  0.092820   \n",
      "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
      "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
      "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
      "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
      "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
      "\n",
      "           s4        s5        s6  \n",
      "0   -0.002592  0.019908 -0.017646  \n",
      "1   -0.039493 -0.068330 -0.092204  \n",
      "2   -0.002592  0.002864 -0.025930  \n",
      "3    0.034309  0.022692 -0.009362  \n",
      "4   -0.002592 -0.031991 -0.046641  \n",
      "5   -0.076395 -0.041180 -0.096346  \n",
      "6   -0.039493 -0.062913 -0.038357  \n",
      "7    0.017703 -0.035817  0.003064  \n",
      "8   -0.002592 -0.014956  0.011349  \n",
      "9   -0.002592  0.067736 -0.013504  \n",
      "10  -0.076395 -0.062913 -0.034215  \n",
      "11   0.071210 -0.096433 -0.059067  \n",
      "12  -0.039493 -0.030751 -0.042499  \n",
      "13  -0.002592  0.038393 -0.013504  \n",
      "14  -0.039493 -0.031991 -0.075636  \n",
      "15   0.108111  0.036056 -0.042499  \n",
      "16  -0.039493  0.052280  0.027917  \n",
      "17   0.034309  0.027368 -0.001078  \n",
      "18  -0.002592 -0.018118 -0.017646  \n",
      "19  -0.039493 -0.008944 -0.054925  \n",
      "20  -0.039493 -0.011901  0.015491  \n",
      "21  -0.039493 -0.072128 -0.017646  \n",
      "22  -0.039493 -0.061177 -0.013504  \n",
      "23   0.071210  0.133599  0.135612  \n",
      "24  -0.002592 -0.025952 -0.054925  \n",
      "25   0.034309  0.019199 -0.034215  \n",
      "26  -0.076395 -0.042572 -0.005220  \n",
      "27  -0.039493 -0.015998  0.040343  \n",
      "28  -0.039493 -0.000609 -0.054925  \n",
      "29  -0.076395  0.059424  0.052770  \n",
      "..        ...       ...       ...  \n",
      "412 -0.002592  0.006209  0.085907  \n",
      "413 -0.039493 -0.035817  0.019633  \n",
      "414  0.091875  0.054724  0.007207  \n",
      "415  0.071210  0.014823  0.003064  \n",
      "416  0.003312 -0.029528  0.036201  \n",
      "417 -0.021412 -0.046879  0.003064  \n",
      "418 -0.002592 -0.021394  0.007207  \n",
      "419 -0.039493 -0.074089 -0.005220  \n",
      "420  0.034309 -0.033249  0.061054  \n",
      "421  0.071210  0.049769  0.015491  \n",
      "422 -0.002592  0.040672 -0.009362  \n",
      "423  0.108111  0.015567 -0.046641  \n",
      "424  0.034309  0.024053  0.023775  \n",
      "425 -0.076395 -0.020289 -0.050783  \n",
      "426  0.057557  0.035462  0.085907  \n",
      "427 -0.039493 -0.045421  0.032059  \n",
      "428  0.034309  0.066048  0.131470  \n",
      "429 -0.024733 -0.025952 -0.038357  \n",
      "430  0.034309 -0.009919 -0.017646  \n",
      "431 -0.039493 -0.014956 -0.001078  \n",
      "432  0.023239  0.055684  0.106617  \n",
      "433 -0.039493 -0.051401 -0.009362  \n",
      "434 -0.039493 -0.045421  0.032059  \n",
      "435 -0.002592 -0.038459 -0.038357  \n",
      "436 -0.076395 -0.061177 -0.046641  \n",
      "437 -0.002592  0.031193  0.007207  \n",
      "438  0.034309 -0.018118  0.044485  \n",
      "439 -0.011080 -0.046879  0.015491  \n",
      "440  0.026560  0.044528 -0.025930  \n",
      "441 -0.039493 -0.004220  0.003064  \n",
      "\n",
      "[442 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# putting the dataset in Pandas DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df =pd.DataFrame(data=diabetes.data,columns=diabetes.feature_names)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df['DiseaseProgression']=diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286377, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04687948,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452837, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00421986,  0.00306441]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=diabetes.data\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=diabetes.target\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,x_train,y_test,y_train=train_test_split(x,y,test_size=0.33,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0821917808219178"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.score(x_train,y_train) #82%correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68., 248., 248., 275.,  72., 248., 248., 275., 248., 275., 248.,\n",
       "        68., 248., 248.,  72.,  72.,  72., 248., 248., 248.,  83., 275.,\n",
       "        72., 275.,  83., 248.,  72.,  72.,  72., 113., 248., 248.,  72.,\n",
       "       248.,  68., 248., 248., 248., 248., 248., 248., 248.,  83., 248.,\n",
       "       275., 248., 275., 248.,  83.,  83.,  68., 248., 248., 275., 248.,\n",
       "        72.,  72.,  72., 275., 248., 248., 113., 275., 275.,  68.,  83.,\n",
       "        83., 248., 248., 248., 275.,  72., 248.,  72., 248., 248., 248.,\n",
       "       248.,  72., 248.,  72.,  72.,  72.,  83.,  72., 248.,  72., 113.,\n",
       "       113., 248., 248.,  83.,  83.,  72.,  72.,  72.,  72.,  72., 248.,\n",
       "       248.,  72., 248.,  72.,  72., 248., 275., 275.,  72.,  72.,  72.,\n",
       "        83.,  72.,  68., 248.,  72., 275.,  72.,  72., 113., 113.,  72.,\n",
       "       248., 275., 248., 248., 248., 248.,  72., 113.,  68.,  72., 248.,\n",
       "       275., 248., 248., 248., 248.,  72., 248.,  72.,  72.,  72., 248.,\n",
       "       248., 248.,  72., 275.,  72., 248.,  72.,  72., 113.,  72.,  68.,\n",
       "       248.,  83.,  72., 248., 248.,  72., 248.,  83., 275.,  72., 275.,\n",
       "       248.,  72.,  72.,  72., 275., 275.,  72., 248., 248., 113., 275.,\n",
       "       275., 248.,  72., 248.,  72., 275., 248., 248.,  72.,  72.,  72.,\n",
       "       248., 275.,  72., 248.,  72.,  83., 248.,  72., 248.,  83., 248.,\n",
       "        72., 248.,  72.,  72.,  72., 248.,  72.,  68.,  72., 248.,  72.,\n",
       "       248., 248., 275.,  72.,  72.,  72., 248., 248.,  72.,  72., 248.,\n",
       "       113.,  72., 248., 248.,  72., 113., 275.,  83., 248.,  72., 248.,\n",
       "        72.,  72., 275., 248., 248.,  72.,  72., 248.,  72., 275., 248.,\n",
       "        72., 113., 113., 275., 248., 248.,  72.,  72., 248.,  72., 248.,\n",
       "        83.,  83., 248.,  72.,  72., 275.,  72., 248.,  83., 248., 275.,\n",
       "       275., 113.,  72.,  72.,  72., 113., 248., 248., 113.,  83., 113.,\n",
       "        72.,  72.,  83., 248., 275.,  72.,  72., 248., 248., 248., 248.,\n",
       "       113., 248.,  83., 275.,  72.,  68., 275., 113.,  72., 248.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=lg.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.006756756756756757\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score:\",accuracy_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix: [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"confusion_matrix:\",confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "        31.0       0.00      0.00      0.00         1\n",
      "        37.0       0.00      0.00      0.00         1\n",
      "        39.0       0.00      0.00      0.00         1\n",
      "        40.0       0.00      0.00      0.00         1\n",
      "        42.0       0.00      0.00      0.00         3\n",
      "        43.0       0.00      0.00      0.00         1\n",
      "        44.0       0.00      0.00      0.00         1\n",
      "        47.0       0.00      0.00      0.00         2\n",
      "        48.0       0.00      0.00      0.00         3\n",
      "        49.0       0.00      0.00      0.00         3\n",
      "        51.0       0.00      0.00      0.00         3\n",
      "        52.0       0.00      0.00      0.00         4\n",
      "        53.0       0.00      0.00      0.00         3\n",
      "        54.0       0.00      0.00      0.00         1\n",
      "        55.0       0.00      0.00      0.00         4\n",
      "        57.0       0.00      0.00      0.00         1\n",
      "        58.0       0.00      0.00      0.00         1\n",
      "        59.0       0.00      0.00      0.00         3\n",
      "        60.0       0.00      0.00      0.00         3\n",
      "        61.0       0.00      0.00      0.00         2\n",
      "        63.0       0.00      0.00      0.00         3\n",
      "        64.0       0.00      0.00      0.00         2\n",
      "        65.0       0.00      0.00      0.00         2\n",
      "        66.0       0.00      0.00      0.00         1\n",
      "        67.0       0.00      0.00      0.00         2\n",
      "        68.0       0.00      0.00      0.00         0\n",
      "        69.0       0.00      0.00      0.00         3\n",
      "        70.0       0.00      0.00      0.00         1\n",
      "        71.0       0.00      0.00      0.00         4\n",
      "        72.0       0.02      0.67      0.04         3\n",
      "        74.0       0.00      0.00      0.00         1\n",
      "        75.0       0.00      0.00      0.00         2\n",
      "        77.0       0.00      0.00      0.00         4\n",
      "        78.0       0.00      0.00      0.00         1\n",
      "        79.0       0.00      0.00      0.00         1\n",
      "        80.0       0.00      0.00      0.00         1\n",
      "        81.0       0.00      0.00      0.00         2\n",
      "        83.0       0.00      0.00      0.00         0\n",
      "        84.0       0.00      0.00      0.00         3\n",
      "        85.0       0.00      0.00      0.00         3\n",
      "        87.0       0.00      0.00      0.00         1\n",
      "        88.0       0.00      0.00      0.00         3\n",
      "        90.0       0.00      0.00      0.00         4\n",
      "        91.0       0.00      0.00      0.00         2\n",
      "        92.0       0.00      0.00      0.00         2\n",
      "        93.0       0.00      0.00      0.00         2\n",
      "        94.0       0.00      0.00      0.00         1\n",
      "        95.0       0.00      0.00      0.00         1\n",
      "        96.0       0.00      0.00      0.00         2\n",
      "        97.0       0.00      0.00      0.00         4\n",
      "        98.0       0.00      0.00      0.00         1\n",
      "        99.0       0.00      0.00      0.00         2\n",
      "       100.0       0.00      0.00      0.00         1\n",
      "       101.0       0.00      0.00      0.00         1\n",
      "       102.0       0.00      0.00      0.00         2\n",
      "       103.0       0.00      0.00      0.00         1\n",
      "       104.0       0.00      0.00      0.00         4\n",
      "       109.0       0.00      0.00      0.00         3\n",
      "       110.0       0.00      0.00      0.00         1\n",
      "       111.0       0.00      0.00      0.00         1\n",
      "       113.0       0.00      0.00      0.00         0\n",
      "       114.0       0.00      0.00      0.00         1\n",
      "       115.0       0.00      0.00      0.00         1\n",
      "       118.0       0.00      0.00      0.00         1\n",
      "       120.0       0.00      0.00      0.00         1\n",
      "       121.0       0.00      0.00      0.00         2\n",
      "       122.0       0.00      0.00      0.00         1\n",
      "       123.0       0.00      0.00      0.00         1\n",
      "       124.0       0.00      0.00      0.00         2\n",
      "       125.0       0.00      0.00      0.00         1\n",
      "       127.0       0.00      0.00      0.00         2\n",
      "       128.0       0.00      0.00      0.00         3\n",
      "       129.0       0.00      0.00      0.00         1\n",
      "       131.0       0.00      0.00      0.00         2\n",
      "       132.0       0.00      0.00      0.00         2\n",
      "       134.0       0.00      0.00      0.00         2\n",
      "       135.0       0.00      0.00      0.00         1\n",
      "       137.0       0.00      0.00      0.00         2\n",
      "       138.0       0.00      0.00      0.00         2\n",
      "       139.0       0.00      0.00      0.00         1\n",
      "       140.0       0.00      0.00      0.00         2\n",
      "       141.0       0.00      0.00      0.00         3\n",
      "       142.0       0.00      0.00      0.00         3\n",
      "       143.0       0.00      0.00      0.00         2\n",
      "       144.0       0.00      0.00      0.00         3\n",
      "       145.0       0.00      0.00      0.00         1\n",
      "       146.0       0.00      0.00      0.00         1\n",
      "       147.0       0.00      0.00      0.00         1\n",
      "       150.0       0.00      0.00      0.00         2\n",
      "       151.0       0.00      0.00      0.00         1\n",
      "       152.0       0.00      0.00      0.00         1\n",
      "       153.0       0.00      0.00      0.00         1\n",
      "       154.0       0.00      0.00      0.00         1\n",
      "       158.0       0.00      0.00      0.00         2\n",
      "       160.0       0.00      0.00      0.00         1\n",
      "       162.0       0.00      0.00      0.00         1\n",
      "       163.0       0.00      0.00      0.00         1\n",
      "       166.0       0.00      0.00      0.00         1\n",
      "       167.0       0.00      0.00      0.00         1\n",
      "       168.0       0.00      0.00      0.00         2\n",
      "       170.0       0.00      0.00      0.00         2\n",
      "       171.0       0.00      0.00      0.00         1\n",
      "       172.0       0.00      0.00      0.00         2\n",
      "       173.0       0.00      0.00      0.00         1\n",
      "       174.0       0.00      0.00      0.00         2\n",
      "       175.0       0.00      0.00      0.00         1\n",
      "       177.0       0.00      0.00      0.00         1\n",
      "       178.0       0.00      0.00      0.00         3\n",
      "       179.0       0.00      0.00      0.00         1\n",
      "       180.0       0.00      0.00      0.00         1\n",
      "       181.0       0.00      0.00      0.00         2\n",
      "       182.0       0.00      0.00      0.00         3\n",
      "       183.0       0.00      0.00      0.00         1\n",
      "       184.0       0.00      0.00      0.00         1\n",
      "       185.0       0.00      0.00      0.00         1\n",
      "       186.0       0.00      0.00      0.00         1\n",
      "       187.0       0.00      0.00      0.00         1\n",
      "       189.0       0.00      0.00      0.00         1\n",
      "       191.0       0.00      0.00      0.00         1\n",
      "       192.0       0.00      0.00      0.00         1\n",
      "       197.0       0.00      0.00      0.00         1\n",
      "       198.0       0.00      0.00      0.00         2\n",
      "       199.0       0.00      0.00      0.00         1\n",
      "       200.0       0.00      0.00      0.00         3\n",
      "       201.0       0.00      0.00      0.00         1\n",
      "       202.0       0.00      0.00      0.00         2\n",
      "       206.0       0.00      0.00      0.00         1\n",
      "       209.0       0.00      0.00      0.00         1\n",
      "       210.0       0.00      0.00      0.00         1\n",
      "       212.0       0.00      0.00      0.00         1\n",
      "       214.0       0.00      0.00      0.00         3\n",
      "       217.0       0.00      0.00      0.00         1\n",
      "       219.0       0.00      0.00      0.00         2\n",
      "       220.0       0.00      0.00      0.00         3\n",
      "       222.0       0.00      0.00      0.00         1\n",
      "       225.0       0.00      0.00      0.00         2\n",
      "       229.0       0.00      0.00      0.00         1\n",
      "       230.0       0.00      0.00      0.00         2\n",
      "       233.0       0.00      0.00      0.00         2\n",
      "       235.0       0.00      0.00      0.00         2\n",
      "       236.0       0.00      0.00      0.00         1\n",
      "       237.0       0.00      0.00      0.00         1\n",
      "       241.0       0.00      0.00      0.00         1\n",
      "       242.0       0.00      0.00      0.00         2\n",
      "       243.0       0.00      0.00      0.00         2\n",
      "       245.0       0.00      0.00      0.00         1\n",
      "       248.0       0.00      0.00      0.00         0\n",
      "       249.0       0.00      0.00      0.00         1\n",
      "       252.0       0.00      0.00      0.00         1\n",
      "       253.0       0.00      0.00      0.00         1\n",
      "       257.0       0.00      0.00      0.00         2\n",
      "       258.0       0.00      0.00      0.00         3\n",
      "       259.0       0.00      0.00      0.00         3\n",
      "       262.0       0.00      0.00      0.00         1\n",
      "       263.0       0.00      0.00      0.00         2\n",
      "       264.0       0.00      0.00      0.00         1\n",
      "       265.0       0.00      0.00      0.00         2\n",
      "       270.0       0.00      0.00      0.00         1\n",
      "       272.0       0.00      0.00      0.00         2\n",
      "       273.0       0.00      0.00      0.00         1\n",
      "       274.0       0.00      0.00      0.00         1\n",
      "       275.0       0.00      0.00      0.00         1\n",
      "       276.0       0.00      0.00      0.00         1\n",
      "       277.0       0.00      0.00      0.00         2\n",
      "       279.0       0.00      0.00      0.00         1\n",
      "       280.0       0.00      0.00      0.00         1\n",
      "       281.0       0.00      0.00      0.00         3\n",
      "       283.0       0.00      0.00      0.00         2\n",
      "       288.0       0.00      0.00      0.00         1\n",
      "       292.0       0.00      0.00      0.00         1\n",
      "       295.0       0.00      0.00      0.00         1\n",
      "       296.0       0.00      0.00      0.00         1\n",
      "       297.0       0.00      0.00      0.00         1\n",
      "       310.0       0.00      0.00      0.00         3\n",
      "       311.0       0.00      0.00      0.00         1\n",
      "       317.0       0.00      0.00      0.00         1\n",
      "       321.0       0.00      0.00      0.00         1\n",
      "       332.0       0.00      0.00      0.00         1\n",
      "       336.0       0.00      0.00      0.00         1\n",
      "       341.0       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.01      0.01      0.01       296\n",
      "   macro avg       0.00      0.00      0.00       296\n",
      "weighted avg       0.00      0.01      0.00       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification_report:\",classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Save the predicted data into csv\n",
    "df=pd.DataFrame(pred)\n",
    "df\n",
    "df.to_csv(\"Diabetes Prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
